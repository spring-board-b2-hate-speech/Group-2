{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO8zohPW4bt8iHfnKw+YDAM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Word2Vec Encoding Method**"],"metadata":{"id":"cXP9C3Ic062t"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bioVPHk8xO3R","executionInfo":{"status":"ok","timestamp":1718856795331,"user_tz":-330,"elapsed":1452,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"285e364f-377b-4e37-87a5-7aff39cbdb27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original DataFrame:\n","   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n","0           0      3            0                   0        3      2   \n","1           1      3            0                   3        0      1   \n","2           2      3            0                   3        0      1   \n","3           3      3            0                   2        1      1   \n","4           4      6            0                   6        0      1   \n","\n","                                               tweet  \\\n","0  retweet as a woman you should not complain abo...   \n","1  retweet boy dats coldtyga down bad for cuffin ...   \n","2  retweet dawg retweet you ever fuck a bitch and...   \n","3                     retweet she look like a tranny   \n","4  retweet the shit you hear about me might be tr...   \n","\n","                                        tweet_tokens  \n","0  ['retweet', 'woman', 'complain', 'cleaning', '...  \n","1  ['retweet', 'boy', 'dat', 'coldtyga', 'bad', '...  \n","2  ['retweet', 'dawg', 'retweet', 'ever', 'fuck',...  \n","3              ['retweet', 'look', 'like', 'tranny']  \n","4  ['retweet', 'shit', 'hear', 'might', 'true', '...  \n"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","# Replace with the actual path to your CSV file\n","df = pd.read_csv('/content/cleaned_dataset.csv')\n","\n","# Display the first few rows to verify\n","print(\"Original DataFrame:\")\n","print(df.head())\n","\n","\n"]},{"cell_type":"code","source":["import ast\n","\n","# Convert string representation of list to actual list\n","df['tweet_tokens'] = df['tweet_tokens'].apply(ast.literal_eval)\n","\n","# Display the first few rows to verify\n","print(\"\\nDataFrame after converting tweet_tokens to lists:\")\n","print(df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NenYF-0myQxY","executionInfo":{"status":"ok","timestamp":1718856803089,"user_tz":-330,"elapsed":1825,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"b9d24ab4-995b-4886-eeb1-7bfe78826204"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","DataFrame after converting tweet_tokens to lists:\n","   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n","0           0      3            0                   0        3      2   \n","1           1      3            0                   3        0      1   \n","2           2      3            0                   3        0      1   \n","3           3      3            0                   2        1      1   \n","4           4      6            0                   6        0      1   \n","\n","                                               tweet  \\\n","0  retweet as a woman you should not complain abo...   \n","1  retweet boy dats coldtyga down bad for cuffin ...   \n","2  retweet dawg retweet you ever fuck a bitch and...   \n","3                     retweet she look like a tranny   \n","4  retweet the shit you hear about me might be tr...   \n","\n","                                        tweet_tokens  \n","0  [retweet, woman, complain, cleaning, house, an...  \n","1  [retweet, boy, dat, coldtyga, bad, cuffin, dat...  \n","2  [retweet, dawg, retweet, ever, fuck, bitch, st...  \n","3                      [retweet, look, like, tranny]  \n","4  [retweet, shit, hear, might, true, might, fake...  \n"]}]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","# Train Word2Vec model\n","word2vec_model = Word2Vec(sentences=df['tweet_tokens'], vector_size=100, window=5, min_count=1, workers=4)\n","\n","# Get the vector size\n","vector_size = word2vec_model.wv.vector_size\n","\n"],"metadata":{"id":"OCXKqEZnyiOP","executionInfo":{"status":"ok","timestamp":1718856847231,"user_tz":-330,"elapsed":2364,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def document_vector(doc):\n","    # Remove out-of-vocabulary words\n","    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n","    # If the document is empty, return a zero vector\n","    if not doc:\n","        return np.zeros(vector_size)\n","    # Calculate the mean vector\n","    return np.mean(word2vec_model.wv[doc], axis=0)\n","\n","# Apply the function to transform tweet_tokens\n","X_vectors = df['tweet_tokens'].apply(document_vector).tolist()\n","X_vectors = np.array(X_vectors)\n","\n","# Display the first few rows to verify\n","print(\"\\nVectorized DataFrame:\")\n","print(X_vectors)\n","print(X_vectors.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9YuRWHeyvSK","executionInfo":{"status":"ok","timestamp":1718856853887,"user_tz":-330,"elapsed":1434,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"a52940d6-cc33-4c19-ded1-746f1bcee4d6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Vectorized DataFrame:\n","[[-0.12281501  0.55791259  0.03236658 ... -0.61398578  0.25563625\n","  -0.69630682]\n"," [-0.06064844  0.46781531 -0.01103297 ... -0.48454204  0.24361667\n","  -0.60603142]\n"," [-0.08893751  0.55862242 -0.02659687 ... -0.55425692  0.28885379\n","  -0.69526631]\n"," ...\n"," [ 0.01220226  0.4365465  -0.03993332 ... -0.50972438  0.41628036\n","  -0.94992763]\n"," [-0.01496591  0.36141133 -0.01601156 ... -0.36901939  0.18593688\n","  -0.46845421]\n"," [-0.06536717  0.23087177  0.03120324 ... -0.26092887  0.09738781\n","  -0.27045333]]\n","(24783, 100)\n"]}]},{"cell_type":"code","source":["# Combine Word2Vec features with other features\n","other_features = df[['hate_speech', 'offensive_language', 'neither']]\n","X_combined = np.hstack((other_features, X_vectors))\n","\n","# Define the target variable\n","y = df['class']\n","\n","# Display the first few rows to verify\n","print(\"\\nCombined DataFrame:\")\n","print(X_combined)\n","print(X_combined.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiLm9QkFz4S0","executionInfo":{"status":"ok","timestamp":1718856867190,"user_tz":-330,"elapsed":520,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"613d4f0c-ea5b-4718-ec86-ac199355e2d0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Combined DataFrame:\n","[[ 0.          0.          3.         ... -0.61398578  0.25563625\n","  -0.69630682]\n"," [ 0.          3.          0.         ... -0.48454204  0.24361667\n","  -0.60603142]\n"," [ 0.          3.          0.         ... -0.55425692  0.28885379\n","  -0.69526631]\n"," ...\n"," [ 0.          3.          0.         ... -0.50972438  0.41628036\n","  -0.94992763]\n"," [ 0.          6.          0.         ... -0.36901939  0.18593688\n","  -0.46845421]\n"," [ 0.          0.          3.         ... -0.26092887  0.09738781\n","  -0.27045333]]\n","(24783, 103)\n"]}]}]}