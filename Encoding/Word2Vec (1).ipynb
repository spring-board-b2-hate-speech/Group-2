{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Word2Vec Encoding Method**"
      ],
      "metadata": {
        "id": "cXP9C3Ic062t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bioVPHk8xO3R",
        "outputId": "8d5e8dbf-c1d4-40e0-d83e-254ef442c94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      1   \n",
            "1           1      3            0                   3        0      0   \n",
            "2           2      3            0                   3        0      0   \n",
            "3           3      3            0                   2        1      0   \n",
            "4           4      6            0                   6        0      0   \n",
            "\n",
            "                                               tweet  \\\n",
            "0  retweet as a woman you should not complain abo...   \n",
            "1  retweet boy dats coldtyga down bad for cuffin ...   \n",
            "2  retweet dawg retweet you ever fuck a bitch and...   \n",
            "3                     retweet she look like a tranny   \n",
            "4  retweet the shit you hear about me might be tr...   \n",
            "\n",
            "                                        tweet_tokens  \n",
            "0  ['retweet', 'woman', 'complain', 'cleaning', '...  \n",
            "1  ['retweet', 'boy', 'dat', 'coldtyga', 'bad', '...  \n",
            "2  ['retweet', 'dawg', 'retweet', 'ever', 'fuck',...  \n",
            "3              ['retweet', 'look', 'like', 'tranny']  \n",
            "4  ['retweet', 'shit', 'hear', 'might', 'true', '...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Replace with the actual path to your CSV file\n",
        "df = pd.read_csv('/content/cleaned_dataset_updated.csv')\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"Original DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# Convert string representation of list to actual list\n",
        "df['tweet_tokens'] = df['tweet_tokens'].apply(ast.literal_eval)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nDataFrame after converting tweet_tokens to lists:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NenYF-0myQxY",
        "outputId": "40c11a37-ed6b-4fcf-f0b1-85e7cdadedfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after converting tweet_tokens to lists:\n",
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      1   \n",
            "1           1      3            0                   3        0      0   \n",
            "2           2      3            0                   3        0      0   \n",
            "3           3      3            0                   2        1      0   \n",
            "4           4      6            0                   6        0      0   \n",
            "\n",
            "                                               tweet  \\\n",
            "0  retweet as a woman you should not complain abo...   \n",
            "1  retweet boy dats coldtyga down bad for cuffin ...   \n",
            "2  retweet dawg retweet you ever fuck a bitch and...   \n",
            "3                     retweet she look like a tranny   \n",
            "4  retweet the shit you hear about me might be tr...   \n",
            "\n",
            "                                        tweet_tokens  \n",
            "0  [retweet, woman, complain, cleaning, house, an...  \n",
            "1  [retweet, boy, dat, coldtyga, bad, cuffin, dat...  \n",
            "2  [retweet, dawg, retweet, ever, fuck, bitch, st...  \n",
            "3                      [retweet, look, like, tranny]  \n",
            "4  [retweet, shit, hear, might, true, might, fake...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=df['tweet_tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get the vector size\n",
        "vector_size = word2vec_model.wv.vector_size\n",
        "\n"
      ],
      "metadata": {
        "id": "OCXKqEZnyiOP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def document_vector(doc):\n",
        "    # Remove out-of-vocabulary words\n",
        "    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
        "    # If the document is empty, return a zero vector\n",
        "    if not doc:\n",
        "        return np.zeros(vector_size)\n",
        "    # Calculate the mean vector\n",
        "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
        "\n",
        "# Apply the function to transform tweet_tokens\n",
        "X_vectors = df['tweet_tokens'].apply(document_vector).tolist()\n",
        "X_vectors = np.array(X_vectors)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nVectorized DataFrame:\")\n",
        "print(X_vectors)\n",
        "print(X_vectors.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9YuRWHeyvSK",
        "outputId": "8b2da4aa-65c8-4c1a-b618-db7bbb99b95d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vectorized DataFrame:\n",
            "[[-0.14082471  0.44016486  0.06225185 ... -0.62547803  0.13013999\n",
            "  -0.54296857]\n",
            " [-0.1067239   0.36742252 -0.00740037 ... -0.50695616  0.13325049\n",
            "  -0.49256691]\n",
            " [-0.13244572  0.42608422 -0.01693738 ... -0.57374227  0.1624656\n",
            "  -0.55834991]\n",
            " ...\n",
            " [ 0.00891974  0.31136045  0.01564116 ... -0.54785264  0.30374619\n",
            "  -0.839293  ]\n",
            " [-0.0532313   0.26881793 -0.00480163 ... -0.37872431  0.10320554\n",
            "  -0.35580322]\n",
            " [-0.06812277  0.19264875  0.0409341  ... -0.27052113  0.04469281\n",
            "  -0.20821074]]\n",
            "(24783, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Word2Vec features with other features\n",
        "other_features = df[['tweet_tokens']]\n",
        "X_combined = np.hstack((other_features, X_vectors))\n",
        "\n",
        "# Define the target variable\n",
        "y = df['class']\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(\"\\nCombined DataFrame:\")\n",
        "print(X_combined)\n",
        "print(X_combined.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiLm9QkFz4S0",
        "outputId": "346344cd-51d8-42ce-8935-3c4f0a0b9817"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined DataFrame:\n",
            "[[list(['retweet', 'woman', 'complain', 'cleaning', 'house', 'andamp', 'man', 'always', 'take', 'trash'])\n",
            "  -0.14082470536231995 0.44016486406326294 ... -0.6254780292510986\n",
            "  0.13013999164104462 -0.5429685711860657]\n",
            " [list(['retweet', 'boy', 'dat', 'coldtyga', 'bad', 'cuffin', 'dat', 'hoe', 'st', 'place'])\n",
            "  -0.10672390460968018 0.36742252111434937 ... -0.506956160068512\n",
            "  0.13325048983097076 -0.49256691336631775]\n",
            " [list(['retweet', 'dawg', 'retweet', 'ever', 'fuck', 'bitch', 'start', 'cry', 'confused', 'shit'])\n",
            "  -0.13244572281837463 0.4260842204093933 ... -0.5737422704696655\n",
            "  0.16246560215950012 -0.5583499073982239]\n",
            " ...\n",
            " [list(['young', 'buck', 'wan', 'na', 'eat', 'dat', 'nigguh', 'like', 'fuckin', 'dis'])\n",
            "  0.008919736370444298 0.3113604485988617 ... -0.547852635383606\n",
            "  0.30374619364738464 -0.8392930030822754]\n",
            " [list(['youu', 'got', 'wild', 'bitch', 'tellin', 'lie'])\n",
            "  -0.05323129519820213 0.2688179314136505 ... -0.3787243068218231\n",
            "  0.10320553928613663 -0.3558032214641571]\n",
            " [list(['ruffled', 'ntac', 'eileen', 'dahlia', 'beautiful', 'color', 'combination', 'pink', 'orange', 'yellow', 'andamp', 'white', 'coll'])\n",
            "  -0.06812277436256409 0.1926487535238266 ... -0.2705211341381073\n",
            "  0.04469280689954758 -0.20821073651313782]]\n",
            "(24783, 101)\n"
          ]
        }
      ]
    }
  ]
}