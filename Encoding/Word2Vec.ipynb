{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNc1bFCcZU52Hx5QqBAHQf+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Word2Vec Encoding Method**"],"metadata":{"id":"cXP9C3Ic062t"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bioVPHk8xO3R","executionInfo":{"status":"ok","timestamp":1720069033622,"user_tz":-330,"elapsed":1386,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"039c7cc8-3645-47a2-bca3-d011c8aba07d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original DataFrame:\n","   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n","0           0      3            0                   0        3      2   \n","1           1      3            0                   3        0      1   \n","2           2      3            0                   3        0      1   \n","3           3      3            0                   2        1      1   \n","4           4      6            0                   6        0      1   \n","\n","                                               tweet  \\\n","0  retweet as a woman you should not complain abo...   \n","1  retweet boy dats coldtyga down bad for cuffin ...   \n","2  retweet dawg retweet you ever fuck a bitch and...   \n","3                     retweet she look like a tranny   \n","4  retweet the shit you hear about me might be tr...   \n","\n","                                        tweet_tokens  \n","0  ['retweet', 'woman', 'complain', 'cleaning', '...  \n","1  ['retweet', 'boy', 'dat', 'coldtyga', 'bad', '...  \n","2  ['retweet', 'dawg', 'retweet', 'ever', 'fuck',...  \n","3              ['retweet', 'look', 'like', 'tranny']  \n","4  ['retweet', 'shit', 'hear', 'might', 'true', '...  \n"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","# Replace with the actual path to your CSV file\n","df = pd.read_csv('/content/cleaned_dataset.csv')\n","\n","# Display the first few rows to verify\n","print(\"Original DataFrame:\")\n","print(df.head())\n","\n","\n"]},{"cell_type":"code","source":["import ast\n","\n","# Convert string representation of list to actual list\n","df['tweet_tokens'] = df['tweet_tokens'].apply(ast.literal_eval)\n","\n","# Display the first few rows to verify\n","print(\"\\nDataFrame after converting tweet_tokens to lists:\")\n","print(df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NenYF-0myQxY","executionInfo":{"status":"ok","timestamp":1720069038780,"user_tz":-330,"elapsed":772,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"d73d8661-77cb-47ea-ad4e-b314c65bdc89"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","DataFrame after converting tweet_tokens to lists:\n","   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n","0           0      3            0                   0        3      2   \n","1           1      3            0                   3        0      1   \n","2           2      3            0                   3        0      1   \n","3           3      3            0                   2        1      1   \n","4           4      6            0                   6        0      1   \n","\n","                                               tweet  \\\n","0  retweet as a woman you should not complain abo...   \n","1  retweet boy dats coldtyga down bad for cuffin ...   \n","2  retweet dawg retweet you ever fuck a bitch and...   \n","3                     retweet she look like a tranny   \n","4  retweet the shit you hear about me might be tr...   \n","\n","                                        tweet_tokens  \n","0  [retweet, woman, complain, cleaning, house, an...  \n","1  [retweet, boy, dat, coldtyga, bad, cuffin, dat...  \n","2  [retweet, dawg, retweet, ever, fuck, bitch, st...  \n","3                      [retweet, look, like, tranny]  \n","4  [retweet, shit, hear, might, true, might, fake...  \n"]}]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","# Train Word2Vec model\n","word2vec_model = Word2Vec(sentences=df['tweet_tokens'], vector_size=100, window=5, min_count=1, workers=4)\n","\n","# Get the vector size\n","vector_size = word2vec_model.wv.vector_size\n","\n"],"metadata":{"id":"OCXKqEZnyiOP","executionInfo":{"status":"ok","timestamp":1720069050017,"user_tz":-330,"elapsed":4760,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def document_vector(doc):\n","    # Remove out-of-vocabulary words\n","    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n","    # If the document is empty, return a zero vector\n","    if not doc:\n","        return np.zeros(vector_size)\n","    # Calculate the mean vector\n","    return np.mean(word2vec_model.wv[doc], axis=0)\n","\n","# Apply the function to transform tweet_tokens\n","X_vectors = df['tweet_tokens'].apply(document_vector).tolist()\n","X_vectors = np.array(X_vectors)\n","\n","# Display the first few rows to verify\n","print(\"\\nVectorized DataFrame:\")\n","print(X_vectors)\n","print(X_vectors.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9YuRWHeyvSK","executionInfo":{"status":"ok","timestamp":1720069056198,"user_tz":-330,"elapsed":1543,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"245ce021-2427-41a4-aaa4-969a2d413e2c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Vectorized DataFrame:\n","[[-0.1281698   0.42272925  0.04509426 ... -0.60607636  0.1591309\n","  -0.57312489]\n"," [-0.0891434   0.36997801 -0.00723159 ... -0.51402587  0.16330306\n","  -0.51962775]\n"," [-0.12536888  0.43876806 -0.01209868 ... -0.58585697  0.18756148\n","  -0.58029068]\n"," ...\n"," [ 0.03422692  0.30399019 -0.01226119 ... -0.56724137  0.31995553\n","  -0.85040873]\n"," [-0.05223104  0.2863552   0.00428885 ... -0.38134488  0.10953305\n","  -0.36331376]\n"," [-0.06535207  0.18472365  0.02876179 ... -0.25548741  0.05174784\n","  -0.21488836]]\n","(24783, 100)\n"]}]},{"cell_type":"code","source":["# Combine Word2Vec features with other features\n","other_features = df[['tweet_tokens']]\n","X_combined = np.hstack((other_features, X_vectors))\n","\n","# Define the target variable\n","y = df['class']\n","\n","# Display the first few rows to verify\n","print(\"\\nCombined DataFrame:\")\n","print(X_combined)\n","print(X_combined.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiLm9QkFz4S0","executionInfo":{"status":"ok","timestamp":1720069212449,"user_tz":-330,"elapsed":466,"user":{"displayName":"Vaishnavi Samal","userId":"00413506782897093810"}},"outputId":"dcb1e640-173d-4872-c90b-b5cf8d9eb887"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Combined DataFrame:\n","[[list(['retweet', 'woman', 'complain', 'cleaning', 'house', 'andamp', 'man', 'always', 'take', 'trash'])\n","  -0.12816980481147766 0.4227292537689209 ... -0.6060763597488403\n","  0.15913090109825134 -0.573124885559082]\n"," [list(['retweet', 'boy', 'dat', 'coldtyga', 'bad', 'cuffin', 'dat', 'hoe', 'st', 'place'])\n","  -0.08914340287446976 0.36997801065444946 ... -0.514025866985321\n","  0.16330306231975555 -0.5196277499198914]\n"," [list(['retweet', 'dawg', 'retweet', 'ever', 'fuck', 'bitch', 'start', 'cry', 'confused', 'shit'])\n","  -0.1253688782453537 0.43876805901527405 ... -0.5858569741249084\n","  0.18756148219108582 -0.580290675163269]\n"," ...\n"," [list(['young', 'buck', 'wan', 'na', 'eat', 'dat', 'nigguh', 'like', 'fuckin', 'dis'])\n","  0.0342269167304039 0.3039901852607727 ... -0.567241370677948\n","  0.3199555277824402 -0.8504087328910828]\n"," [list(['youu', 'got', 'wild', 'bitch', 'tellin', 'lie'])\n","  -0.052231043577194214 0.286355197429657 ... -0.38134488463401794\n","  0.10953304916620255 -0.363313764333725]\n"," [list(['ruffled', 'ntac', 'eileen', 'dahlia', 'beautiful', 'color', 'combination', 'pink', 'orange', 'yellow', 'andamp', 'white', 'coll'])\n","  -0.06535206735134125 0.1847236454486847 ... -0.2554874122142792\n","  0.051747843623161316 -0.21488836407661438]]\n","(24783, 101)\n"]}]}]}